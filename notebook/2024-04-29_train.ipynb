{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331b1e71-1b2a-4ae2-8934-07730cd7282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803f725a-dc46-40f0-aee4-759ccc610202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 7\n",
      "dataset_dir: preprocess/make_webdataset/all\n",
      "scale_dir: output/preprocess/stats_for_norm/base\n",
      "test_path: input/test.parquet\n",
      "model:\n",
      "  input_size: 556\n",
      "  hidden_sizes:\n",
      "  - 256\n",
      "  - 256\n",
      "  - 256\n",
      "  output_size: 368\n",
      "num_workers: 8\n",
      "train_batch_size: 400\n",
      "valid_batch_size: 800\n",
      "max_epochs: 10\n",
      "early_stopping_patience: 2\n",
      "accelerator: auto\n",
      "precision: '32'\n",
      "gradient_clip_val: 1.0\n",
      "accumulate_grad_batches: 1\n",
      "check_val_every_n_epoch: 1\n",
      "lr: 0.001\n",
      "monitor: valid_loss\n",
      "monitor_mode: min\n",
      "scheduler:\n",
      "  use_one_epoch_warmup: false\n",
      "ema:\n",
      "  use_ema: true\n",
      "  decay: 0.9975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../experiments/000_baseline\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config.yaml\", overrides=[\"debug=True\"], return_hydra_config=True\n",
    "    )\n",
    "    print(OmegaConf.to_yaml(cfg.exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb80276a-f14f-44ba-be35-4bee491e6a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name: notebook/base\n",
      "ouput_path: /kaggle/working/output/notebook/base\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import webdataset as wds\n",
    "from google.cloud import storage\n",
    "from pytorch_lightning import (\n",
    "    LightningDataModule,\n",
    "    LightningModule,\n",
    "    Trainer,\n",
    "    seed_everything,\n",
    ")\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "runtime_choices = cfg.hydra.runtime.choices\n",
    "exp_name = f\"notebook/{runtime_choices.exp}\"\n",
    "print(f\"exp_name: {exp_name}\")\n",
    "output_path = Path(cfg.dir.output_dir) / exp_name\n",
    "print(f\"ouput_path: {output_path}\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74104a5c-7bb2-495e-813f-d32dc0800526",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(cfg.exp.seed)\n",
    "\n",
    "pl_logger = WandbLogger(\n",
    "    name=exp_name,\n",
    "    project=\"kaggle-leap\",\n",
    "    mode=\"disabled\" if cfg.debug else None,\n",
    ")\n",
    "pl_logger.log_hyperparams(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c03048c-f1b0-4182-86f5-219d26a77472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c23bd7-6016-485e-880b-e7ede96c7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a78467a1-118f-4d51-ac05-3cdfdb92de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mean = np.load(Path(cfg.exp.scale_dir) / \"input_mean.npy\")\n",
    "input_max = np.load(Path(cfg.exp.scale_dir) / \"input_max.npy\")\n",
    "input_min = np.load(Path(cfg.exp.scale_dir) / \"input_min.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705faa9b-df00-4644-be48-fa72afb84a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3a8d04c-d609-4700-9136-8020b9239df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeapLightningDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scaler = Scaler(cfg)\n",
    "        self.cfg = cfg\n",
    "        self.rng = random.Random(self.cfg.exp.seed)\n",
    "        self.train_years = (1, 8) if cfg.debug is False else (1, 2)\n",
    "        self.valid_years = (8, 10) if cfg.debug is False else (9, 10)\n",
    "        self.train_dataset = self._make_dataset(\"train\")\n",
    "        self.valid_dataset = self._make_dataset(\"valid\")\n",
    "\n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, cfg, test_df, scaler):\n",
    "            self.cfg = cfg\n",
    "            self.scaler = scaler\n",
    "            # 提供データは cam_in_SNOWHICE は削除済みなので削除しないが、idを削除する\n",
    "            self.x = test_df[:, 1:].to_numpy()\n",
    "            self.dtype = torch.float64 if \"64\" in cfg.exp.precision else torch.float32\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.x.shape[0]\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return torch.from_numpy(self.scaler.scale_input(self.x[index])).to(\n",
    "                self.dtype\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return (\n",
    "            wds.WebLoader(\n",
    "                self.train_dataset,\n",
    "                batch_size=None,\n",
    "                num_workers=self.cfg.exp.num_workers,\n",
    "            )\n",
    "            .shuffle(7)\n",
    "            .batched(\n",
    "                batchsize=self.cfg.exp.train_batch_size,\n",
    "                partial=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return (\n",
    "            wds.WebLoader(\n",
    "                self.valid_dataset,\n",
    "                batch_size=None,\n",
    "                num_workers=self.cfg.exp.num_workers,\n",
    "            )\n",
    "            .shuffle(7)\n",
    "            .batched(\n",
    "                batchsize=self.cfg.exp.valid_batch_size,\n",
    "                partial=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.test_df = pl.read_parquet(\n",
    "            self.cfg.exp.test_path, n_rows=(None if self.cfg.debug is False else 500)\n",
    "        )\n",
    "        self.test_dataset = self.TestDataset(self.cfg, self.test_df, self.scaler)\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.cfg.exp.valid_batch_size,\n",
    "            num_workers=self.cfg.exp.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "    def _get_basename(self, year):\n",
    "        month = \"02\" if year == 1 else \"01\"\n",
    "        return (\n",
    "            f\"shards_000{year}\"\n",
    "            if self.cfg.debug is False\n",
    "            else f\"shards_000{year}-{month}\"\n",
    "        )\n",
    "\n",
    "    def _get_webdataset_url_list(self, bucket_name, prefix):\n",
    "        storage_client = storage.Client()\n",
    "        blobs = storage_client.list_blobs(bucket_name, prefix=prefix, delimiter=None)\n",
    "        return [\n",
    "            f\"pipe:gsutil cat gs://{self.cfg.dir.gcs_bucket}/{path.name}\"\n",
    "            for path in blobs\n",
    "            if path.name.endswith(\"tar\")\n",
    "        ]\n",
    "\n",
    "    def _make_tar_list(self, mode=\"train\"):\n",
    "        tar_list = []\n",
    "        start_year, end_year = self.train_years if mode == \"train\" else self.valid_years\n",
    "        for year in range(start_year, end_year):\n",
    "            # debug時は１月のデータのみ\n",
    "            tmp = self._get_webdataset_url_list(\n",
    "                self.cfg.dir.gcs_bucket,\n",
    "                f\"{self.cfg.dir.gcs_base_dir}/{self.cfg.exp.dataset_dir}/{self._get_basename(year)}\",\n",
    "            )\n",
    "            tar_list += tmp\n",
    "        # 1/data_skip_mod の数にする\n",
    "        if self.cfg.exp.data_skip_mod:\n",
    "            tar_list = tar_list[:: self.cfg.exp.data_skip_mod]\n",
    "        print(mode, f\"{len(tar_list)=}\")\n",
    "        return tar_list\n",
    "\n",
    "    def _sum_dataset_sizes(self, bucket_name, prefix):\n",
    "        storage_client = storage.Client()\n",
    "        blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "        total_size = 0\n",
    "        for blob in blobs:\n",
    "            if blob.name.endswith(\"dataset-size.json\"):\n",
    "                json_data = json.loads(blob.download_as_string())\n",
    "                dataset_size = json_data[\"dataset size\"]\n",
    "                total_size += dataset_size\n",
    "        return total_size\n",
    "\n",
    "    def _get_dataset_size(self, mode=\"train\"):\n",
    "        total_size = 0\n",
    "        start_year, end_year = self.train_years if mode == \"train\" else self.valid_years\n",
    "        for year in range(start_year, end_year):\n",
    "            tmp = self._sum_dataset_sizes(\n",
    "                self.cfg.dir.gcs_bucket,\n",
    "                f\"{self.cfg.dir.gcs_base_dir}/{self.cfg.exp.dataset_dir}/{self._get_basename(year)}\",\n",
    "            )\n",
    "            total_size += tmp\n",
    "        if self.cfg.exp.data_skip_mod:\n",
    "            total_size = total_size // self.cfg.exp.data_skip_mod\n",
    "        return total_size\n",
    "\n",
    "    def _make_dataset(self, mode=\"train\"):\n",
    "        tar_list = self._make_tar_list(mode)\n",
    "        dataset_size = self._get_dataset_size(mode)\n",
    "        dtype = torch.float64 if \"64\" in self.cfg.exp.precision else torch.float32\n",
    "        print(mode, dataset_size)\n",
    "        return (\n",
    "            wds.WebDataset(urls=tar_list, shardshuffle=True)\n",
    "            .shuffle(100, rng=self.rng)\n",
    "            .decode()\n",
    "            .to_tuple(\"input.npy\", \"output.npy\")\n",
    "            .map_tuple(\n",
    "                lambda x: torch.tensor(\n",
    "                    self.scaler.scale_input(\n",
    "                        np.delete(x, 375, 0)  # cam_in_SNOWHICE は削除\n",
    "                    ),\n",
    "                    dtype=dtype,\n",
    "                ),\n",
    "                lambda y: torch.tensor(self.scaler.scale_output(y), dtype=dtype),\n",
    "            )\n",
    "            .with_length(dataset_size)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b4eef01-1d62-4458-98e2-9c589c0842a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from timm.utils import ModelEmaV2\n",
    "from torch import nn\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "class LeapModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the layers\n",
    "        layers = []\n",
    "        previous_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(previous_size, hidden_size))\n",
    "            layers.append(nn.LayerNorm(hidden_size))  # Normalization layer\n",
    "            layers.append(nn.LeakyReLU(inplace=True))  # Activation\n",
    "            previous_size = hidden_size\n",
    "\n",
    "        layers.append(nn.Linear(previous_size, output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3688f2c-2986-45be-9773-77bc9b09257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeapLightningModule(LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = LeapModel(**cfg.exp.model)\n",
    "        self.loss_fc = nn.MSELoss()  # Using MSE for regression\n",
    "        self.model_ema = None\n",
    "        if self.cfg.exp.ema.use_ema:\n",
    "            print(\"Using EMA\")\n",
    "            self.model_ema = ModelEmaV2(self.model, self.cfg.exp.ema.decay)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        mode = \"train\"\n",
    "        x, y = batch\n",
    "        out = self.__pred(x, mode)\n",
    "        loss = self.loss_fc(out, y)\n",
    "        self.log(\n",
    "            f\"{mode}_loss\",\n",
    "            loss.detach().item(),\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        mode = \"valid\"\n",
    "        x, y = batch\n",
    "        out = self.__pred(x, mode)\n",
    "        loss = self.loss_fc(out, y)\n",
    "        self.log(\n",
    "            f\"{mode}_loss\",\n",
    "            loss.detach().item(),\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        mode = \"test\"\n",
    "        x = batch\n",
    "        out = self.__pred(x, mode)\n",
    "        return out\n",
    "\n",
    "    def __pred(self, x, mode: str) -> torch.Tensor:\n",
    "        if (mode == \"valid\" or mode == \"test\") and (self.model_ema is not None):\n",
    "            out = self.model_ema.module(x)\n",
    "        else:\n",
    "            out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    def on_after_backward(self):\n",
    "        if self.model_ema is not None:\n",
    "            self.model_ema.update(self.model)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.cfg.exp.lr)\n",
    "\n",
    "        \"\"\"\n",
    "        scheduler = tc.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=cfg.exp.lr,\n",
    "            steps_per_epoch=len(train_dataloader),\n",
    "            epochs=cfg.exp.epochs + 1,\n",
    "            pct_start=0.1,\n",
    "        )\n",
    "        \"\"\"\n",
    "        # 1epoch分をwarmupとするための記述\n",
    "        num_warmup_steps = (\n",
    "            math.ceil(self.trainer.max_steps / self.cfg.exp.epoch) * 1\n",
    "            if self.cfg.exp.scheduler.use_one_epoch_warmup\n",
    "            else 0\n",
    "        )\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_training_steps=self.trainer.max_steps,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "        )\n",
    "\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a102640-8e05-4fc7-9d7e-0bfe7c8b6bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 774144\n",
      "valid 857088\n",
      "Using EMA\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    RichModelSummary,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "monitor = f\"{cfg.exp.monitor}\"\n",
    "dm = LeapLightningDataModule(cfg)\n",
    "model = LeapLightningModule(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8eb45adb-97c3-4bef-8662-ad15c069db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    dirpath=output_path / \"checkpoints\",\n",
    "    verbose=True,\n",
    "    monitor=monitor,\n",
    "    mode=cfg.exp.monitor_mode,\n",
    "    save_top_k=1,\n",
    "    save_last=False,\n",
    "    enable_version_counter=False,\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(\"epoch\")\n",
    "progress_bar = RichProgressBar(leave=True)\n",
    "model_summary = RichModelSummary(max_depth=2)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    patience=cfg.exp.early_stopping_patience,\n",
    "    mode=cfg.exp.monitor_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14acce9d-1536-409d-bcd8-fc331674aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model            │ LeapModel  │  370 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ model.layers     │ Sequential │  370 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ loss_fc          │ MSELoss    │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ model_ema        │ ModelEmaV2 │  370 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ model_ema.module │ LeapModel  │  370 K │\n",
       "└───┴──────────────────┴────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model            │ LeapModel  │  370 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ model.layers     │ Sequential │  370 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ loss_fc          │ MSELoss    │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ model_ema        │ ModelEmaV2 │  370 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ model_ema.module │ LeapModel  │  370 K │\n",
       "└───┴──────────────────┴────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 740 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 740 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 740 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 740 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1a359f04d54e308c6c84af9da9eb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66da3caf4d14309949811079645e9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e5dd05a893481ea68e8d2b10a16bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cfg.debug:\n",
    "    cfg.exp.max_epochs = 2\n",
    "\n",
    "trainer = Trainer(\n",
    "    default_root_dir=output_path,\n",
    "    accelerator=cfg.exp.accelerator,\n",
    "    precision=cfg.exp.precision,\n",
    "    max_epochs=cfg.exp.max_epochs,\n",
    "    max_steps=cfg.exp.max_epochs * len(dm.train_dataset) // cfg.exp.train_batch_size,\n",
    "    gradient_clip_val=cfg.exp.gradient_clip_val,\n",
    "    accumulate_grad_batches=cfg.exp.accumulate_grad_batches,\n",
    "    logger=pl_logger,\n",
    "    log_every_n_steps=1,\n",
    "    limit_train_batches=None if cfg.debug is False else 5,\n",
    "    limit_val_batches=None if cfg.debug is False else 5,\n",
    "    # deterministic=True,\n",
    "    callbacks=[\n",
    "        checkpoint_cb,\n",
    "        lr_monitor,\n",
    "        progress_bar,\n",
    "        model_summary,\n",
    "        early_stopping,\n",
    "    ],\n",
    "    # resume_from_checkpoint=resume_from,\n",
    "    num_sanity_val_steps=0,\n",
    "    # sync_batchnorm=True,\n",
    "    check_val_every_n_epoch=cfg.exp.check_val_every_n_epoch,\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "test_predictions = trainer.predict(model, dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d8dbbb3-20a5-4a70-ac5a-aee25005ee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.3267,  0.1700,  0.4306,  ..., -0.2172,  0.1716,  0.0549],\n",
       "         [ 0.3267,  0.1700,  0.4306,  ..., -0.2172,  0.1716,  0.0549],\n",
       "         [ 0.3267,  0.1700,  0.4306,  ..., -0.2172,  0.1716,  0.0549],\n",
       "         ...,\n",
       "         [ 0.3267,  0.1700,  0.4306,  ..., -0.2172,  0.1716,  0.0549],\n",
       "         [ 0.3267,  0.1700,  0.4306,  ..., -0.2172,  0.1716,  0.0549],\n",
       "         [ 0.3267,  0.1700,  0.4306,  ..., -0.2172,  0.1716,  0.0549]])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caught CTRL-C (signal 2) - exiting\n",
      "Caught CTRL-C (signal 2) - exiting\n"
     ]
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bcece-35a2-4ece-a32a-d9147aa7fc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
