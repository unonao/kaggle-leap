seed: 7

modes: [train, valid, test, viz]


dataset_dir: input/make_webdataset_batch/all
scale_dir: misc/normalize_v5
norm_name: "0"
test_path: input/test.parquet
sample_submission_path: input/sample_submission.parquet
viz_notebook_path: notebook/result_viz_002_for_v5.ipynb
pred_checkpoint_path: null


# data 指定期間内のデータを利用。skip_modで間引く
train_start: [1, 2] #1の2月
train_end: [8, 1]
valid_start: [8, 2]
valid_end: [9, 1]

train_data_skip_mod: 16
valid_data_skip_mod: 7

eps: 1e-60
outlier_std_rate: 10
additional_replace_target: [] # ${cols.weight_zero_index_list}　以外で必要あれば
fill_target: [
  ptend_q0002_12,
  ptend_q0002_13,
  ptend_q0002_14,
  ptend_q0002_15,
  ptend_q0002_16,
  ptend_q0002_17,
  ptend_q0002_18,
  ptend_q0002_19,
  ptend_q0002_20,
  ptend_q0002_21,
  ptend_q0002_22,
  ptend_q0002_23,
  ptend_q0002_24,
  ptend_q0002_25,
  ptend_q0002_26,
  ptend_q0002_27,
]

# model
model:
  input_size: 556
  hidden_sizes : [2048, 1024, 1024, 512]
  output_size: 368

# Training
optimizer: 
  name: RAdam
  lr: 5e-3
  weight_decay: 0
num_workers: 8
train_batch_size: 4
valid_batch_size: 4

max_epochs: 50

early_stopping_patience: 2

# trainer
accelerator: auto
precision: "32" # https://lightning.ai/docs/pytorch/stable/common/trainer.html#precision
gradient_clip_val: 1.0
accumulate_grad_batches: 1
check_val_every_n_epoch: 1

# LightningModule

scheduler:
  use_one_epoch_warmup: True

ema:
  use_ema: True
  decay: 0.9975